# Constitutional Fine-Tuning Pipeline Configuration

constitution:
  # Raw GitHub URL for the constitution markdown
  url: "https://raw.githubusercontent.com/anthropics/claude-constitution/refs/heads/main/20260120-constitution.md"
  # Local cache path (relative to project root)
  cache_path: "data/constitution.md"
  # Replace "Claude" with this model name in principles
  target_model_name: "Qwen"

datagen:
  # OpenRouter API configuration
  api_base_url: "https://openrouter.ai/api/v1"
  api_key_env: "OPENROUTER_API_KEY"
  # Model to use for generating training data
  model: "anthropic/claude-sonnet-4"
  # Number of examples to generate per principle-category pair
  examples_per_principle: 3
  # Max principles sampled per category (limits total volume)
  max_principles_per_category: 30
  # Max concurrent API requests
  max_concurrency: 10
  # Output path for generated training data
  output_path: "data/training_data.jsonl"
  # Max retries per API call
  max_retries: 3

training:
  # Base model to fine-tune
  base_model: "Qwen/Qwen3-8B"
  # LoRA configuration
  lora_rank: 32
  # Optimizer
  adam:
    learning_rate: 5.0e-4
    beta1: 0.9
    beta2: 0.95
    eps: 1.0e-8
  # Training parameters
  batch_size: 32
  epochs: 3
  max_seq_length: 2048
  # Learning rate schedule
  warmup_fraction: 0.05
  # Checkpointing
  save_every_steps: 50
  # Final model name
  run_name: "constitutional-qwen3-8b"

  # Tinker service URL (null = use default)
  tinker_base_url: null
